{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import requests\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import re\n",
    "import ssl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basePath=''\n",
    "flagPFcode=True\n",
    "pfam='PF00806'\n",
    "param=''\n",
    "filename=''\n",
    "rangeSeq=10\n",
    "PDBCodeStructure=[]\n",
    "maxLongSeq=550\n",
    "minLongSeq=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(len(sys.argv) > 1):    \n",
    "    param=sys.argv[1]\n",
    "    posDot=param.find('.')\n",
    "    if(param==\"default\"):\n",
    "        print(\"Default config\")\n",
    "    elif (posDot>0):\n",
    "        extensionFile=param[posDot:]\n",
    "        if(extensionFile==\".txt\"):\n",
    "            print(\"Input file is a sequence. Exiting this process for family fragments.\")\n",
    "            sys.exit()\n",
    "            \n",
    "        flagPFcode=False\n",
    "        filename=param\n",
    "    else:\n",
    "        pfam=param\n",
    "\n",
    "if(len(sys.argv) > 2): \n",
    "    param2=sys.argv[2]\n",
    "    dirAux=os.path.join(param2, \"target\")\n",
    "    isdir = os.path.isdir(dirAux) \n",
    "        \n",
    "    if not isdir:        \n",
    "        try:\n",
    "            os.makedirs(dirAux)\n",
    "        except:\n",
    "            print(\"Error with directory: \"+dirAux)\n",
    "            sys.exit()\n",
    "\n",
    "    basePath=os.path.join(param2, \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quitar los cambios de linea en una secuencia\n",
    "def preProcessText(data, initPoint, endPoint):\n",
    "    seq=data\n",
    "    pos=seq.find('\\n')\n",
    "    \n",
    "    after=seq[pos+1:]\n",
    "    after=after.replace('\\n','')\n",
    "    \n",
    "    if(len(after)-2*rangeSeq>=minLongSeq):\n",
    "        after=after[initPoint+rangeSeq:endPoint-rangeSeq+1]\n",
    "    \n",
    "    print(\"Sequence length: \"+str(len(after)))\n",
    "\n",
    "    if((len(after)<=maxLongSeq) and (len(after)>=minLongSeq)):\n",
    "        print(\"Sequence length (\"+str(len(after))+\") between range valid to prediction - [\"+str(minLongSeq)+\", \"+str(maxLongSeq)+\"]\")\n",
    "        before=seq[:pos+1]\n",
    "        full=before+after\n",
    "        return (True, full)\n",
    "    \n",
    "    print(\"Sequence length (\"+str(len(after))+\") not valid to prediction. Range valid - [\"+str(minLongSeq)+\", \"+str(maxLongSeq)+\"]\")\n",
    "    return (False, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos el archivo\n",
    "def response2fasta (nameFile,response, initPoint, endPoint):\n",
    "    print(\"Preprocessing \"+ nameFile)\n",
    "    rpta=preProcessText(response.text, initPoint, endPoint)\n",
    "    \n",
    "    if(rpta[0]):\n",
    "        text_file = open(nameFile, \"w\")\n",
    "        text_file.write(rpta[1])\n",
    "        text_file.close()\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correctSeq(x):\n",
    "    x=x.replace('.','')\n",
    "    x=x.replace('-','')\n",
    "    return x.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos el archivo\n",
    "def df2fastaIndividual (dfIn, type):\n",
    "    if(type==1):\n",
    "        preName=basePath+'target/is_'\n",
    "    else:\n",
    "        preName=basePath+'target/target_'\n",
    "\n",
    "    #Organizamos la información tal cual la estructura inicial\n",
    "    dfAux=pd.DataFrame()\n",
    "    dfAux[\"agrupado\"]=dfIn[\"encabezado\"]+ os.linesep+ dfIn[\"secuencia\"]+ os.linesep\n",
    "   \n",
    "    listContent = dfAux['agrupado'].tolist()\n",
    "    listName = dfIn['id'].tolist()\n",
    "    \n",
    "    for i in range(len(listName)):\n",
    "        nameFile=preName+listName[i]+'_'+str(i)+'.fasta' #is: seq independient\n",
    "        print(\"Generating file: \"+ nameFile)\n",
    "        text_file = open(nameFile, \"w\")\n",
    "        text_file.write(listContent[i])\n",
    "        text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos el FASTA desde Pfam\n",
    "if flagPFcode:\n",
    "    try:\n",
    "        urlFasta='https://pfam.xfam.org/family/alignment/download/format?acc='+pfam+'&alnType=full&format=fasta&order=t&case=l&gaps=default&download=1'\n",
    "        ssl._create_default_https_context = ssl._create_unverified_context\n",
    "        filename = wget.download(urlFasta)\n",
    "        print(\"File Fasta downloaded:\")\n",
    "        print(filename)\n",
    "    except:\n",
    "        print(\"Fail downloading Fasta\")\n",
    "        sys.exit()\n",
    "else:\n",
    "    filename=param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename='PF00806_full.txt'\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_DP_TR = pd.read_csv('SP_TR.txt', sep=\" \",header=None)\n",
    "df_DP_TR = pd.read_csv('SP_collection.txt', sep=\" \",header=None)\n",
    "df_DP_TR.rename({0: 'uniprotAccession', 1: 'uniprotId'}, axis=1, inplace=True)\n",
    "df_DP_TR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open(filename, 'r')\n",
    "linesDocInput = file1.readlines()\n",
    " \n",
    "tipoDoc=1 #1:Fasta 2:Stocolmo\n",
    "seqIds=[]\n",
    "count = 0\n",
    "encabezados=[]\n",
    "ids=[]\n",
    "secuencias=[]\n",
    "flagSeq=True\n",
    "lineSeq=''\n",
    "\n",
    "for line in linesDocInput:\n",
    "    count += 1\n",
    "\n",
    "    if (count==1):\n",
    "        posTipoDoc=line.find('#')\n",
    "        if posTipoDoc>=0:\n",
    "            tipoDoc=2\n",
    "            print(\"Input in Stockholm format\")\n",
    "        else:\n",
    "            print(\"Input in Fasta format\")\n",
    "    \n",
    "    if tipoDoc==1:\n",
    "        posHeaderFlag=line.find('>')\n",
    "        if (posHeaderFlag>=0): #Es encabezado\n",
    "            if count==1:\n",
    "                flagSeq=False\n",
    "            else:\n",
    "                flagSeq=True\n",
    "            fin=line.find('/')\n",
    "            sub=(line.strip())[1:fin]        \n",
    "\n",
    "            encabezados.append(line.strip())\n",
    "            ids.append(sub.strip())\n",
    "        else:\n",
    "            if flagSeq:\n",
    "                secuencias.append(lineSeq.strip())\n",
    "                lineSeq=''\n",
    "                flagSeq=False                \n",
    "            lineSeq=lineSeq+line.strip() #concatena las secuencias encontradas\n",
    "            \n",
    "\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfGeneral = pd.DataFrame(list(zip(encabezados, ids, secuencias)),\n",
    "               columns =['encabezado', 'id', 'secuencia'])\n",
    "dfGeneral.head()\n",
    "dfGeneral.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertir a DF\n",
    "dfAccessions = pd.DataFrame(ids, columns =['ids2search'])\n",
    "dfAccessions=dfAccessions.drop_duplicates()\n",
    "print(\"N° items:\",dfAccessions.shape)\n",
    "dfAccessions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtener los uniprot accessions a partir de los IDs\n",
    "merged_inner = pd.merge(left=df_DP_TR, right=dfAccessions, left_on='uniprotId', right_on='ids2search')\n",
    "merged_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lo convertimos a lista\n",
    "accessions2search = merged_inner['uniprotAccession'].tolist()\n",
    "accessions2search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtenerInfoEstructura(rsp):\n",
    "    #Obtenemos la entrada de Uniprot para poder linkearlo a su PDB\n",
    "    uniprot_acc=\"\"\n",
    "    interpro_name=\"\"\n",
    "    pfam=\"\"\n",
    "    pdb_accession=\"\"\n",
    "    uniprot_id=\"\"\n",
    "\n",
    "    uniprot_id=rsp[\"responseHeader\"][\"params\"][\"q\"]\n",
    "    numPDBFound=rsp[\"response\"][\"numFound\"]\n",
    "    print(uniprot_id)\n",
    "\n",
    "    if(numPDBFound!=0):\n",
    "        uniprot_acc=rsp[\"response\"][\"docs\"][0][\"entry_uniprot_accession\"][0]\n",
    "        #interpro_name=rsp[\"response\"][\"docs\"][0][\"interpro_repeat_name\"][0]\n",
    "        pfam=rsp[\"response\"][\"docs\"][0][\"pfam\"][0]\n",
    "        pdb_accession=rsp[\"response\"][\"docs\"][0][\"pdb_accession\"]\n",
    "\n",
    "        print(\"Uniprot accession: \", uniprot_acc)\n",
    "        print(\"Interpro Name: \", interpro_name)\n",
    "        print(\"Num. PDB found: \", numPDBFound)\n",
    "        print(\"PDB accession: \", pdb_accession)\n",
    "        print(\"PFAM: \", pfam)\n",
    "        print(\"---------\")\n",
    "\n",
    "        PDBCodeStructure.append(pdb_accession)\n",
    "        \n",
    "        return True\n",
    "    else:\n",
    "        print(\"--\")\n",
    "        print(\"No se obtuvieron más datos\")\n",
    "        print(\"---------\")\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dat='BAT1_PARRH'\n",
    "#dat='BAT1_MYCRK'\n",
    "#seq=['BAT1_MYCRK','BAT1_PARRH']\n",
    "\n",
    "conEstructura=[]\n",
    "for dat in accessions2search:\n",
    "    url='https://www.ebi.ac.uk/pdbe/search/pdb/select?q=uniprot_accession:'+dat+'&wt=json'\n",
    "    response = requests.get(url, data=[])\n",
    "    rsp=response.json()\n",
    "    #rsp\n",
    "    if (obtenerInfoEstructura(rsp)):\n",
    "        conEstructura.append(dat)\n",
    "        \n",
    "print(\"Tienen estructura: \", conEstructura)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertir a DF\n",
    "df_conEstructura = pd.DataFrame(conEstructura, columns =['accessionsEstructura'])\n",
    "df_conEstructura.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtener los uniprot ID a partir de los accessions\n",
    "merged_inner2 = pd.merge(left=df_DP_TR, right=df_conEstructura, left_on='uniprotAccession', right_on='accessionsEstructura')\n",
    "merged_inner2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfGeneral.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenemos los datos de encabezados y secuencia de los que tienen estructura\n",
    "#dfConEstructuras = dfGeneral[dfGeneral.id.isin(merged_inner2['uniprotId'])]\n",
    "#dfConEstructuras.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenemos los datos de encabezados y secuencia de los que tienen estructura\n",
    "dfSinEstructuras = dfGeneral[~dfGeneral.id.isin(merged_inner2['uniprotId'])]\n",
    "dfSinEstructuras.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Organizamos la información tal cual la estructura inicial\n",
    "#dfAux=pd.DataFrame()\n",
    "#dfAux[\"agrupado\"]=dfConEstructuras[\"encabezado\"]+ os.linesep+dfConEstructuras[\"secuencia\"]\n",
    "#dfAux.head()\n",
    "#dfConEstructuras2=dfConEstructuras.copy()\n",
    "#dfConEstructuras2['secuencia'] = dfConEstructuras2['secuencia'].apply(correctSeq)\n",
    "#dfConEstructuras2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generar archivos\n",
    "#df2fastaIndividual(dfConEstructuras2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos el archivo\n",
    "#print(pfam)\n",
    "#nombre=pfam\n",
    "#if (dfAux.size!=0):\n",
    "    #np.savetxt('target/'+nombre+'_target.fasta', dfAux.values, fmt='%s')\n",
    "#else:\n",
    "    #print(\"No se obtuvo ninguna secuencia que tenga estructura en PDB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====================================================================================\n",
    "#====================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROCESAMOS LAS SECUENCIAS QUE NO TIENEN ESTRUCTURAS\n",
    "\n",
    "#Alternativa 1 (IN): Eliminacion o union de repetidas con mejor inicio y fin-> se saca el uniprot_accession, se buscan en archivos el uniprot_id y se busca la secuencia completa\n",
    "#Alternativa 2 (IS): Un archivo fasta por cada secuencia (check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternativa1:\n",
    "dfSinEstructuras1=dfSinEstructuras.copy()\n",
    "dfSinEstructuras1.shape\n",
    "dfSinEstructuras1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIniIndexSeq(x):\n",
    "    pos1=x.find('/')\n",
    "    pos2=x.find('-')\n",
    "    return x[pos1+1:pos2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEndIndexSeq(x):\n",
    "    pos1=x.find('-')\n",
    "    pos2=len(x)\n",
    "    return x[pos1+1:pos2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSinEstructuras1['iniIndex'] = dfSinEstructuras1['encabezado']. apply(getIniIndexSeq)\n",
    "dfSinEstructuras1['endIndex'] = dfSinEstructuras1['encabezado']. apply(getEndIndexSeq)\n",
    "dfSinEstructuras1.head()\n",
    "dfSinEstructuras1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_innerAux=pd.DataFrame(dfSinEstructuras1, columns =['id','iniIndex','endIndex'])\n",
    "merged_innerAux['iniIndex'] = pd.to_numeric(merged_innerAux['iniIndex'])\n",
    "merged_innerAux['endIndex'] = pd.to_numeric(merged_innerAux['endIndex'])\n",
    "merged_innerAux.dtypes\n",
    "merged_innerAux.shape\n",
    "merged_innerAux.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxMin=merged_innerAux.groupby(['id']).min()\n",
    "auxMin=pd.DataFrame(auxMin, columns =['iniIndex'])\n",
    "auxMin.reset_index(level=0, inplace=True)\n",
    "auxMin.shape\n",
    "auxMin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxMax=merged_innerAux.groupby(['id']).max()\n",
    "auxMax=pd.DataFrame(auxMax, columns =['endIndex'])\n",
    "auxMax.reset_index(level=0, inplace=True)\n",
    "auxMax.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_inner4 = pd.merge(left=auxMin, right=auxMax, left_on='id', right_on='id')\n",
    "merged_inner4.head()\n",
    "#merged_inner4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prueba=merged_inner4.copy()\n",
    "#prueba[\"resta\"]=prueba[\"endIndex\"]-prueba[\"iniIndex\"]\n",
    "#prueba.head()\n",
    "#prueba[\"resta2\"]=prueba[\"resta\"]>500\n",
    "#prueba[prueba[\"resta\"]>500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lo convertimos a lista\n",
    "id_seqs = merged_inner4['id'].tolist()\n",
    "iniIndexSeq = merged_inner4['iniIndex'].tolist()\n",
    "endIndexSeq = merged_inner4['endIndex'].tolist()\n",
    "id_seqs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=0\n",
    "for item in id_seqs:\n",
    "    url='https://www.uniprot.org/uniprot/'+item+'.fasta'\n",
    "    rspta = requests.get(url, data=[])\n",
    "    #print(rspta.text)\n",
    "    if (len(rspta.text)!=0):\n",
    "        rptaFile=response2fasta(basePath+'target/nr_'+item+'_'+str(counter)+'.fasta', rspta, iniIndexSeq[counter], endIndexSeq[counter])  #nr: no repeat\n",
    "        if rptaFile:\n",
    "            counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternativa2:\n",
    "dfSinEstructuras2=dfSinEstructuras.copy()\n",
    "dfSinEstructuras2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSinEstructuras2['secuencia'] = dfSinEstructuras2['secuencia']. apply(correctSeq)\n",
    "dfSinEstructuras2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generar archivos\n",
    "df2fastaIndividual(dfSinEstructuras2, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descargando PDB de la secuencia con los fragmentos con estructura\n",
    "if len(PDBCodeStructure)>0:\n",
    "    dirAux=os.path.join(basePath, \"auxFiles\")\n",
    "    isdir = os.path.isdir(dirAux) \n",
    "        \n",
    "    if not isdir:        \n",
    "        try:\n",
    "            os.makedirs(dirAux)\n",
    "        except:\n",
    "            print(\"Error with directory: \"+dirAux)\n",
    "            sys.exit()\n",
    "\n",
    "    try:\n",
    "        urlFasta='https://files.rcsb.org/download/'+PDBCodeStructure[0]+'.pdb'\n",
    "        filename = wget.download(urlFasta, out=dirAux)\n",
    "    except:\n",
    "        print(\"Fail downloading PDB\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e5030792b3492f6b12d94f1f48beca3d8e59ec05fd59d0aaaa48e684281ed297"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
